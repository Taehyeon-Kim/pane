# Test Design: Story 5.2 - Build & Release Automation Scripts

**Date**: 2025-11-19
**Designer**: Quinn (Test Architect)
**Story**: 5.2 - Build & Release Automation Scripts
**Implementation**: `scripts/build-release.sh` (Bash script)

---

## Test Strategy Overview

**Test Framework**: BATS (Bash Automated Testing System)
**Installation**: `npm install -g bats` or via Homebrew

**Coverage Summary**:
- **Total test scenarios**: 47
- **Unit-style tests**: 18 (38%)
- **Integration-style tests**: 23 (49%)
- **E2E tests**: 6 (13%)
- **Priority distribution**: P0: 21, P1: 18, P2: 6, P3: 2

**Test Categories**:
1. Prerequisite validation (7 tests)
2. Flag parsing and help system (5 tests)
3. Platform detection (4 tests)
4. Build execution (8 tests)
5. Artifact organization (6 tests)
6. Archive and checksum generation (5 tests)
7. Metadata generation (4 tests)
8. Error handling (6 tests)
9. CI compatibility (2 tests)

**Target Coverage**: ≥80% automated scenario coverage (47 scenarios designed)

---

## Test Scenarios by Acceptance Criteria

### AC1: Create `scripts/build-release.sh` script

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-UNIT-001 | Unit | P0 | Script exists and is executable | Critical infrastructure validation |
| 5.2-UNIT-002 | Unit | P0 | Script has proper shebang (`#!/usr/bin/env bash`) | POSIX compliance requirement |
| 5.2-UNIT-003 | Unit | P0 | Script sets strict error handling (`set -e -u -o pipefail`) | Error handling standard from Story 5.1 |

**Coverage**: 3 tests, all P0

---

### AC2: Build workspace binaries (`pane`, `claude-tips`)

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-001 | Integration | P0 | Native build produces both binaries | Core functionality - must work |
| 5.2-INT-002 | Integration | P0 | Build command includes `--workspace` flag | Ensures all workspace members built |
| 5.2-INT-003 | Integration | P1 | Binaries exist in expected paths (`target/release/pane`, `target/release/claude-tips`) | Path validation |
| 5.2-INT-004 | Integration | P2 | Build output displays progress messages | User experience validation |

**Coverage**: 4 tests (2 P0, 1 P1, 1 P2)

---

### AC3: Release profile usage (opt-level=3, lto=true, strip=true)

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-005 | Integration | P0 | Build uses `--release` flag | Critical for optimization |
| 5.2-UNIT-004 | Unit | P1 | Binary size is reasonable (<5MB per binary) | Validates strip=true working |
| 5.2-E2E-001 | E2E | P2 | Binary execution succeeds (smoke test) | Validates build produces working binaries |

**Coverage**: 3 tests (1 P0, 1 P1, 1 P2)

**Note**: Release profile config in Cargo.toml, not script - tests verify applied correctly

---

### AC4: Cross-compilation support (macOS x86_64, ARM64, Linux x86_64)

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-UNIT-005 | Unit | P0 | `detect_platform()` identifies host correctly | Foundation for auto-detection |
| 5.2-UNIT-006 | Unit | P0 | Target validation accepts all supported platforms | Input validation critical |
| 5.2-UNIT-007 | Unit | P0 | Target validation rejects unsupported platforms | Security - prevent invalid targets |
| 5.2-INT-006 | Integration | P1 | `--target x86_64-apple-darwin` builds successfully | macOS Intel support |
| 5.2-INT-007 | Integration | P1 | `--target aarch64-apple-darwin` builds successfully | macOS ARM support |
| 5.2-INT-008 | Integration | P1 | `--target x86_64-unknown-linux-gnu` builds successfully | Linux support |
| 5.2-E2E-002 | E2E | P0 | Cross-compile from macOS to Linux using `cross` | Critical CI workflow |

**Coverage**: 7 tests (4 P0, 3 P1)

**Test Strategy**: Mock cargo/cross in integration tests, use real tools in E2E

---

### AC5: Organize artifacts in `dist/` directory

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-009 | Integration | P0 | `dist/` directory created with correct structure | Core requirement |
| 5.2-INT-010 | Integration | P0 | Directory structure is `dist/v{version}/{target}/` | Naming convention compliance |
| 5.2-UNIT-008 | Unit | P0 | `get_version()` extracts correct version from Cargo.toml | Version parsing critical |
| 5.2-INT-011 | Integration | P1 | Binaries copied to correct target subdirectory | File organization |
| 5.2-INT-012 | Integration | P1 | `--clean` flag removes old `dist/` before build | Cleanup functionality |
| 5.2-INT-013 | Integration | P2 | Multiple builds to same version directory coexist | Multi-target scenario |

**Coverage**: 6 tests (3 P0, 2 P1, 1 P2)

---

### AC6: Binary compression (tar.gz format)

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-014 | Integration | P0 | Archive created with naming `pane-v{version}-{target}.tar.gz` | Naming convention |
| 5.2-INT-015 | Integration | P0 | Archive contains both binaries (`pane`, `claude-tips`) | Content validation |
| 5.2-INT-016 | Integration | P1 | Archive stored in `dist/v{version}/` directory | Location compliance |
| 5.2-UNIT-009 | Unit | P1 | Archive integrity verified (can extract successfully) | Quality check |
| 5.2-INT-017 | Integration | P2 | Build output displays archive size | User feedback |

**Coverage**: 5 tests (2 P0, 2 P1, 1 P2)

---

### AC7: SHA256 checksum file generation

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-018 | Integration | P0 | Checksum file created with `.sha256` extension | Naming requirement |
| 5.2-INT-019 | Integration | P0 | Checksum matches actual archive SHA256 | Integrity validation critical |
| 5.2-UNIT-010 | Unit | P1 | Platform-appropriate checksum command used (`sha256sum` vs `shasum`) | macOS/Linux compatibility |
| 5.2-INT-020 | Integration | P2 | Checksum displayed in build output | User feedback |

**Coverage**: 4 tests (2 P0, 1 P1, 1 P2)

---

### AC8: Build metadata (version, git commit, build date)

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-021 | Integration | P0 | `build-metadata.json` created in `dist/v{version}/` | Metadata requirement |
| 5.2-UNIT-011 | Unit | P0 | Metadata contains all required fields (version, git_commit, build_date, targets, rust_version) | Schema validation |
| 5.2-UNIT-012 | Unit | P1 | Git commit extraction works (`git rev-parse --short HEAD`) | Git integration |
| 5.2-UNIT-013 | Unit | P1 | Build date in ISO-8601 format | Format compliance |
| 5.2-INT-022 | Integration | P2 | Metadata includes artifacts array with checksums | Extended schema |
| 5.2-INT-023 | Integration | P2 | Metadata displayed in build output | User feedback |

**Coverage**: 6 tests (2 P0, 2 P1, 2 P2)

---

### AC9: Clear error messages on build failure

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-UNIT-014 | Unit | P0 | Error when Rust toolchain not found | Critical prerequisite |
| 5.2-UNIT-015 | Unit | P0 | Error when git not available | Metadata dependency |
| 5.2-INT-024 | Integration | P0 | Error on cargo build failure with actionable message | Build failure handling |
| 5.2-UNIT-016 | Unit | P0 | Error when unsupported target specified | Input validation |
| 5.2-UNIT-017 | Unit | P1 | Error when `cross` tool missing for cross-compilation | Cross-compile dependency |
| 5.2-INT-025 | Integration | P1 | Error messages output to stderr (`>&2`) | Standard error handling |
| 5.2-UNIT-018 | Unit | P1 | Script exits with code 1 on validation errors | Exit code standard |
| 5.2-INT-026 | Integration | P2 | Script exits with code 2 on missing prerequisites | Exit code differentiation |

**Coverage**: 8 tests (4 P0, 3 P1, 1 P2)

---

### AC10: CI environment compatibility (GitHub Actions)

#### Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-E2E-003 | E2E | P0 | Script runs non-interactively in CI environment (`CI=true`) | CI requirement |
| 5.2-E2E-004 | E2E | P0 | Script respects `GITHUB_ACTIONS=true` environment variable | GitHub Actions compatibility |
| 5.2-INT-027 | Integration | P1 | No prompts or user interaction during build | Non-interactive validation |
| 5.2-INT-028 | Integration | P1 | Exit code 0 on successful CI build | CI success detection |
| 5.2-E2E-005 | E2E | P2 | Artifacts uploadable in GitHub Actions workflow | CI integration |

**Coverage**: 5 tests (2 P0, 2 P1, 1 P2)

---

## Additional Test Scenarios (Comprehensive Coverage)

### Flag Parsing and Help System

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-UNIT-019 | Unit | P0 | `--help` flag displays usage information | Help system critical |
| 5.2-UNIT-020 | Unit | P1 | `--dry-run` flag prevents actual execution | Dry-run validation |
| 5.2-UNIT-021 | Unit | P1 | `--clean` flag sets CLEAN variable | Flag parsing |
| 5.2-UNIT-022 | Unit | P1 | `--target` flag accepts valid target | Target flag parsing |
| 5.2-UNIT-023 | Unit | P2 | Unknown flags trigger error with helpful message | Error handling UX |

---

### Integration Scenarios (Multi-Flag Combinations)

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-INT-029 | Integration | P1 | `--dry-run --target <triple>` shows planned actions | Combined flags |
| 5.2-INT-030 | Integration | P1 | `--clean --target <triple>` removes old artifacts | Combined flags |
| 5.2-INT-031 | Integration | P2 | `--dry-run --clean` shows cleanup actions | Combined flags |

---

### E2E Real-World Scenarios

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 5.2-E2E-006 | E2E | P0 | Complete macOS native build produces valid distributable | End-to-end validation |
| 5.2-E2E-007 | E2E | P1 | Complete Linux build in Docker produces valid distributable | Linux platform validation |

---

## Risk Coverage

**Mapping to Identified Risks** (from QA gate review):

| Risk ID | Test Scenarios | Mitigation |
|---------|----------------|------------|
| TEST-001 | All 47 automated tests | Automated test suite addresses missing regression protection |
| DOC-001 | 5.2-UNIT-017, 5.2-INT-026 | Exit code validation ensures consistency |
| VAL-001 | 5.2-UNIT-008 | Version extraction with jq fallback tested |
| SAFE-001 | 5.2-INT-013 | Multi-target build scenario validates concurrent safety |

---

## Test Implementation Recommendations

### Test File Structure

```bash
tests/
└── scripts/
    ├── setup_suite.bash          # Shared test setup
    ├── teardown_suite.bash       # Shared test cleanup
    ├── test_prerequisites.bats   # AC9: Prerequisite validation (7 tests)
    ├── test_flags.bats           # Flags and help (5 tests)
    ├── test_platform.bats        # AC4: Platform detection (4 tests)
    ├── test_build.bats           # AC2, AC3: Build execution (8 tests)
    ├── test_artifacts.bats       # AC5: Artifact organization (6 tests)
    ├── test_compression.bats     # AC6, AC7: Archives and checksums (9 tests)
    ├── test_metadata.bats        # AC8: Metadata generation (6 tests)
    ├── test_ci.bats              # AC10: CI compatibility (5 tests)
    └── helpers/
        ├── mock_cargo.bash       # Mock cargo commands
        ├── mock_git.bash         # Mock git commands
        └── assertions.bash       # Custom assertions
```

### Mocking Strategy

**Unit-style tests**:
- Mock `cargo`, `git`, `tar`, `sha256sum` commands
- Test individual functions in isolation
- Use BATS `load` to import script functions

**Integration-style tests**:
- Mock external commands but test full script flow
- Use temporary directories for `dist/` output
- Validate file system changes

**E2E tests**:
- Use real Rust toolchain, git, tar
- Run on actual platforms (macOS, Linux via Docker)
- Verify actual binaries work

### Test Environment Setup

```bash
# setup_suite.bash
export BATS_TEST_TMPDIR="$(mktemp -d)"
export DIST_DIR="$BATS_TEST_TMPDIR/dist"
export MOCK_CARGO="$BATS_TEST_DIRNAME/helpers/mock_cargo.bash"

# Mock binaries for testing
mkdir -p "$BATS_TEST_TMPDIR/bin"
export PATH="$BATS_TEST_TMPDIR/bin:$PATH"
```

### Example Test Implementation

```bash
# test_prerequisites.bats

@test "5.2-UNIT-014: Error when Rust toolchain not found" {
  # Remove cargo from PATH
  PATH="/usr/bin:/bin" run scripts/build-release.sh

  [ "$status" -eq 2 ]
  [[ "$output" =~ "Rust toolchain not found" ]]
  [[ "$output" =~ "https://rustup.rs" ]]
}

@test "5.2-INT-001: Native build produces both binaries" {
  # Mock cargo to create fake binaries
  mock_cargo_success

  run scripts/build-release.sh

  [ "$status" -eq 0 ]
  [ -f "target/release/pane" ]
  [ -f "target/release/claude-tips" ]
}

@test "5.2-INT-018: Checksum file created with .sha256 extension" {
  mock_successful_build

  run scripts/build-release.sh

  [ "$status" -eq 0 ]
  [ -f "dist/v0.1.0/pane-v0.1.0-$(uname -m)-apple-darwin.tar.gz.sha256" ]
}
```

---

## Recommended Execution Order

**CI Pipeline Order**:

1. **P0 Unit Tests** (18 tests, ~30 seconds)
   - Fail fast on basic validation issues
   - Quick feedback loop

2. **P0 Integration Tests** (11 tests, ~2 minutes)
   - Core functionality validation
   - Mocked cargo/git for speed

3. **P1 Tests** (18 tests, ~3 minutes)
   - Important but non-blocking scenarios

4. **E2E Tests** (6 tests, ~10 minutes)
   - Real builds on actual platforms
   - Run in parallel on macOS and Linux

5. **P2+ Tests** (8 tests, ~1 minute)
   - Nice-to-have coverage
   - Can skip in PR checks, run in nightly

**Total Estimated Execution Time**: ~15-20 minutes (with parallelization)

---

## Test Coverage Goals

| Metric | Target | Current | Gap |
|--------|--------|---------|-----|
| Automated Scenario Coverage | ≥80% | 0% | **47 scenarios needed** |
| P0 Test Coverage | 100% | 0% | **21 P0 tests needed** |
| P1 Test Coverage | ≥80% | 0% | **18 P1 tests needed** |
| AC Coverage | 100% | 100% (manual) | **Automate manual tests** |
| Error Path Coverage | ≥90% | 0% | **8 error scenarios needed** |

---

## Quality Checklist

- [x] Every AC has test coverage (10/10 ACs covered)
- [x] Test levels are appropriate (unit for logic, integration for flows, E2E for real builds)
- [x] No duplicate coverage across levels (verified)
- [x] Priorities align with business risk (P0 for critical infrastructure)
- [x] Test IDs follow naming convention (5.2-{LEVEL}-{SEQ})
- [x] Scenarios are atomic and independent (each test standalone)
- [x] Risk coverage complete (all 4 risks from gate review addressed)
- [x] Mocking strategy defined (unit/integration use mocks, E2E uses real tools)

---

## Implementation Effort Estimate

**Total Effort**: 2-3 days (as estimated in QA review technical debt)

**Breakdown**:
- Setup BATS framework and helpers: 4 hours
- Implement unit-style tests (23 tests): 8 hours
- Implement integration-style tests (18 tests): 8 hours
- Implement E2E tests (6 tests): 4 hours
- CI integration and documentation: 2 hours

**Priority 1 Minimum** (P0 + P1 tests): 39 tests = ~1.5 days

---

## Success Criteria

**Test Suite Acceptance**:
- [ ] All P0 tests passing (21 tests)
- [ ] ≥80% of P1 tests passing (15/18 tests)
- [ ] E2E tests passing on macOS and Linux
- [ ] CI pipeline integrated and green
- [ ] Test execution time <20 minutes
- [ ] Test coverage report ≥80% scenario coverage

**Quality Gate Impact**:
- Current Gate: CONCERNS (80/100) → Target Gate: PASS (95/100)
- Current Reliability NFR: CONCERNS → Target: PASS
- Technical Debt: High → Low (automated regression protection in place)

---

## Next Steps

1. **Immediate**: Implement P0 unit tests (prerequisite validation, core functions)
2. **Short-term**: Implement P0 integration tests (build flows, error handling)
3. **Medium-term**: Add E2E tests and CI integration
4. **Long-term**: Expand to P1/P2 tests for comprehensive coverage

**Re-review Trigger**: After P0 + P1 tests implemented, request QA re-review for gate status update.

---

**Test Design Completed**: 2025-11-19
**Next Action**: Development team implements test suite per this design
**Gate File Reference**: `docs/qa/gates/5.2-build-release-automation-scripts.yml`
